[{"uri":"https://thienluhoan.github.io/workshop-template/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Văn A\nSố điện thoại: 0989888999\nEmail: Anguyenvan@gmail.com\nTrường: Đại học Sư phạm Kỹ thuật TP.HCM\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/","title":"Chuẩn bị tài nguyên","tags":[],"description":"","content":"Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBài thu hoạch “GenAI-powered App-DB Modernization workshop” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBài thu hoạch “GenAI-powered App-DB Modernization workshop” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/","title":"Tạo một Gateway Endpoint","tags":[],"description":"","content":" Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Nhật ký công việc AWS \u0026amp; Dự án Nhật ký này ghi lại hành trình 12 tuần của tôi thông qua chương trình đào tạo AWS và phát triển dự án cuối kỳ. Bắt đầu từ ngày 8 tháng 9 năm 2025, tôi đã hoàn thành khóa đào tạo AWS toàn diện bao gồm 7 module, tiếp theo là nghiên cứu chuyên sâu và phát triển một ứng dụng serverless full-stack.\nCấu trúc chương trình Chương trình 12 tuần được cấu trúc thành hai giai đoạn chính:\nGiai đoạn 1: Đào tạo AWS (Tuần 1-8) Bao gồm 7 module AWS toàn diện Thực hành lab cho từng dịch vụ Nhiệm dịch thuật blog hoàn thành vào Tuần 5 (ngày 10 tháng 10) Giai đoạn 2: Dự án cuối kỳ (Tuần 9-12) Nghiên cứu chuyên sâu các dịch vụ AWS nâng cao Thiết kế và lập kế hoạch kiến trúc Triển khai end-to-end ứng dụng sẵn sàng cho production Phân tích theo tuần Tuần 1 (8/9-14/9): Kiến thức AWS cơ bản \u0026amp; Thiết lập tài khoản\nCác khái niệm điện toán đám mây và cơ sở hạ tầng toàn cầu của AWS Tạo tài khoản AWS với các phương thức bảo mật tốt nhất Công cụ quản lý và tối ưu hóa chi phí cơ bản Tuần 2 (15/9-21/9): VPC \u0026amp; Mạng\nThiết kế và triển khai Virtual Private Cloud Bảo mật mạng với Security Groups và NACLs Các khái niệm VPN, Direct Connect và Load Balancing Tuần 3 (22/9-28/9): Amazon EC2 - Tính toán cốt lõi\nCác loại instance EC2, AMIs và tùy chọn lưu trữ Cấu hình EBS volumes và Instance Store Quản lý Key pairs và truy cập SSH Tuần 4 (29/9-5/10): EC2 nâng cao \u0026amp; Auto Scaling\nEC2 User Data và Metadata Auto Scaling Groups và policies EFS cho lưu trữ chia sẻ và dịch vụ di chuyển Tuần 5 (6/10-12/10): Dịch vụ lưu trữ AWS \u0026amp; Dịch thuật Blog\nTìm hiểu sâu về S3 và các lớp lưu trữ Dịch thuật blog hoàn thành vào ngày 10 tháng 10 Website tĩnh S3 và tích hợp CloudFront Tuần 6 (13/10-19/10): Bảo mật, IAM \u0026amp; Ôn tập\nMô hình trách nhiệm chia sẻ và IAM Amazon Cognito và AWS Organizations Ôn tập toàn diện Module 1-5 Tuần 7 (20/10-26/10): Dịch vụ Database\nRDS, Aurora và DynamoDB Redshift cho data warehousing ElastiCache cho caching strategies Tuần 8 (27/10-2/11): Phân tích dữ liệu \u0026amp; Khởi động dự án\nCác khái niệm Data Lake với Glue, Athena, QuickSight Các mẫu DynamoDB nâng cao Lập kế hoạch kiến trúc dự án cuối kỳ Giai đoạn dự án cuối kỳ (Tuần 9-12) Tuần 9 (3/11-9/11): Nghiên cứu dịch vụ AWS\nTìm hiểu sâu về Cognito cho authentication WAF cho bảo mật ứng dụng Công cụ phát triển: CodeCommit, CodeBuild, CodePipeline Infrastructure as Code với Terraform Framework Amplify và các mẫu Lambda nâng cao Tuần 10 (10/11-16/11): Thiết kế kiến trúc\nKiến trúc hệ thống và microservices Thiết kế cơ sở hạ tầng với Terraform Kiến trúc database và bảo mật Lập kế hoạch CI/CD pipeline Cơ sở hạ tầng toàn cầu với CloudFront và Route 53 Tuần 11 (17/11-23/11): Triển khai Backend\nTriển khai cơ sở hạ tầng Terraform Phát triển Lambda functions Thiết lập database với RDS và DynamoDB Tích hợp authentication Cognito Triển khai CI/CD pipeline Tuần 12 (24/11-30/11): Frontend \u0026amp; Triển khai Production\nPhát triển frontend với Amplify Cấu hình CloudFront và Route 53 Triển khai WAF cho bảo mật Testing và bảo đảm chất lượng Triển khai production và monitoring Thành tựu chính ✅ Hoàn thành 7 module AWS toàn diện với lab thực hành ✅ Dịch thuật nội dung blog kỹ thuật (ngày 10 tháng 10) ✅ Thiết kế và triển khai ứng dụng serverless full-stack ✅ Thành thạo 15+ dịch vụ AWS ✅ Xây dựng cơ sở hạ tầng production-ready với IaC ✅ Triển khai CI/CD pipeline hoàn chỉnh ✅ Áp dụng các phương thức bảo mật tốt nhất trong toàn bộ dự án\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.1-week1/","title":"Nhật ký Tuần 1","tags":[],"description":"","content":"Mục tiêu Tuần 1: Hoàn thành Module 01: Kiến thức cơ bản về AWS Hiểu các khái niệm điện toán đám mây và cơ sở hạ tầng toàn cầu của AWS Thiết lập tài khoản AWS với các cấu hình bảo mật phù hợp Công việc cần thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Hướng dẫn và giới thiệu thực tập - Xem lại lộ trình đào tạo AWS - Thiết lập môi trường phát triển 08/09/2025 08/09/2025 Hướng dẫn FCJ 2 - Học Module 01-01: Cloud Computing là gì - Lợi ích của Cloud Computing - Điều gì làm AWS khác biệt 09/09/2025 09/09/2025 AWS Cloud Journey 3 - Học Module 01-02: Cơ sở hạ tầng toàn cầu của AWS - Data Centers, Availability Zones, Regions - Edge Locations 10/09/2025 10/09/2025 AWS Cloud Journey 4 - Học Module 01-03: Công cụ quản lý AWS - AWS Console, CLI, SDK - Tối ưu hóa chi phí AWS 11/09/2025 11/09/2025 AWS Cloud Journey 5 - Học Module 01-04: Hỗ trợ AWS - Các gói hỗ trợ - Trusted Advisor 12/09/2025 12/09/2025 AWS Cloud Journey 6-7 - Thực hành Lab: Module 01-Lab01 - Tạo tài khoản AWS - Thiết lập MFA - Tạo users admin 13-14/09/2025 14/09/2025 AWS Cloud Journey Thành tựu Tuần 1: Hiểu các khái niệm cơ bản về điện toán đám mây và lợi ích của việc áp dụng đám mây Hiểu về cơ sở hạ tầng toàn cầu của AWS bao gồm Regions, Availability Zones, và Edge Locations Nắm được kiến thức về các công cụ quản lý dịch vụ AWS (Console, CLI, SDK) Hiểu các chiến lược tối ưu hóa chi phí và các mô hình giá của AWS Hiểu về các gói hỗ trợ khác nhau của AWS và khi nào sử dụng Tạo thành công tài khoản AWS với các cấu hình bảo mật phù hợp (MFA được bật) Tạo nhóm và users admin theo best practices của AWS Tạo access keys cho truy cập chương trình Khó khăn đối mặt: Xác thực phương thức thanh toán khi tạo tài khoản AWS Hiểu sự khác biệt giữa các gói hỗ trợ khác nhau của AWS Giải pháp đã thực hiện: Sử dụng thẻ tín dụng quốc tế để xác thực tài khoản AWS Tạo bảng so sánh các gói hỗ trợ AWS để hiểu rõ hơn Kế hoạch Tuần tới: Bắt đầu Module 02: AWS VPC và Bảo mật Học các khái niệm VPC, subnets, và các thành phần mạng Tìm hiểu về security groups và NACLs "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.2-week2/","title":"Nhật ký Tuần 2","tags":[],"description":"","content":"Mục tiêu Tuần 2: Hoàn thành Module 02: AWS VPC và Bảo mật Hiểu các khái niệm Virtual Private Cloud và các thành phần Tìm hiểu về bảo mật mạng và các tùy chọn kết nối Công việc cần thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Học Module 02-01: Giới thiệu AWS VPC - Khái niệm VPC, Public/Private subnets - CIDR blocks và IP addressing 15/09/2025 15/09/2025 AWS Cloud Journey 2 - Học Module 02-02: Các thành phần VPC - Route Tables, ENI, EIP - Internet Gateway, NAT Gateway 16/09/2025 16/09/2025 AWS Cloud Journey 3 - Học Module 02-03: Bảo mật VPC - Security Groups vs NACLs - Best practices 17/09/2025 17/09/2025 AWS Cloud Journey 4 - Học Kết nối Mạng - VPN Site-to-Site - Direct Connect, Load Balancers 18/09/2025 18/09/2025 AWS Cloud Journey 5 - Thực hành Lab: Module 02-Lab03 - Tạo VPC và subnets - Cấu hình Internet Gateway 19/09/2025 19/09/2025 AWS Cloud Journey 6-7 - Tiếp tục Thực hành Lab - Thiết lập routing - Test kết nối mạng 20-21/09/2025 21/09/2025 AWS Cloud Journey Thành tựu Tuần 2: Nắm vững các khái niệm VPC bao gồm public vs private subnets Hiểu về các thành phần VPC: Route Tables, ENI, EIP, VPC Endpoints Hiểu về các tùy chọn kết nối mạng: IGW, NAT Gateway, VPN Phân biệt được Security Groups (stateful) và NACLs (stateless) Tạo thành công VPC tùy chỉnh với cấu hình subnet phù hợp Cấu hình Internet Gateway cho truy cập public subnet Thiết lập route tables để điều hướng traffic phù hợp Test kết nối mạng giữa các thành phần Khó khăn đối mặt: Nhầm lẫn giữa routing của public và private subnet Hiểu khi nào sử dụng Security Groups vs NACLs Cấu hình route tables phù hợp Giải pháp đã thực hiện: Tạo sơ đồ routing để trực quan hóa traffic flow Xây dựng bảng so sánh Security Groups vs NACLs Hướng dẫn cấu hình route table từng bước Kế hoạch Tuần tới: Bắt đầu Module 03: Amazon EC2 Học về các loại instance và tính năng của EC2 Tìm hiểu về AMI, EBS, và các tùy chọn lưu trữ "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại phần này, bạn cần tóm tắt các nội dung trong workshop mà bạn dự tính sẽ làm.\nIoT Weather Platform for Lab Research Giải pháp AWS Serverless hợp nhất cho giám sát thời tiết thời gian thực 1. Tóm tắt điều hành IoT Weather Platform được thiết kế dành cho nhóm ITea Lab tại TP. Hồ Chí Minh nhằm nâng cao khả năng thu thập và phân tích dữ liệu thời tiết. Nền tảng hỗ trợ tối đa 5 trạm thời tiết, có khả năng mở rộng lên 10–15 trạm, sử dụng thiết bị biên Raspberry Pi kết hợp cảm biến ESP32 để truyền dữ liệu qua MQTT. Nền tảng tận dụng các dịch vụ AWS Serverless để cung cấp giám sát thời gian thực, phân tích dự đoán và tiết kiệm chi phí, với quyền truy cập giới hạn cho 5 thành viên phòng lab thông qua Amazon Cognito.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nCác trạm thời tiết hiện tại yêu cầu thu thập dữ liệu thủ công, khó quản lý khi có nhiều trạm. Không có hệ thống tập trung cho dữ liệu hoặc phân tích thời gian thực, và các nền tảng bên thứ ba thường tốn kém và quá phức tạp.\nGiải pháp\nNền tảng sử dụng AWS IoT Core để tiếp nhận dữ liệu MQTT, AWS Lambda và API Gateway để xử lý, Amazon S3 để lưu trữ (bao gồm data lake), và AWS Glue Crawlers cùng các tác vụ ETL để trích xuất, chuyển đổi, tải dữ liệu từ S3 data lake sang một S3 bucket khác để phân tích. AWS Amplify với Next.js cung cấp giao diện web, và Amazon Cognito đảm bảo quyền truy cập an toàn. Tương tự như Thingsboard và CoreIoT, người dùng có thể đăng ký thiết bị mới và quản lý kết nối, nhưng nền tảng này hoạt động ở quy mô nhỏ hơn và phục vụ mục đích sử dụng nội bộ. Các tính năng chính bao gồm bảng điều khiển thời gian thực, phân tích xu hướng và chi phí vận hành thấp.\nLợi ích và hoàn vốn đầu tư (ROI)\nGiải pháp tạo nền tảng cơ bản để các thành viên phòng lab phát triển một nền tảng IoT lớn hơn, đồng thời cung cấp nguồn dữ liệu cho những người nghiên cứu AI phục vụ huấn luyện mô hình hoặc phân tích. Nền tảng giảm bớt báo cáo thủ công cho từng trạm thông qua hệ thống tập trung, đơn giản hóa quản lý và bảo trì, đồng thời cải thiện độ tin cậy dữ liệu. Chi phí hàng tháng ước tính 0,66 USD (theo AWS Pricing Calculator), tổng cộng 7,92 USD cho 12 tháng. Tất cả thiết bị IoT đã được trang bị từ hệ thống trạm thời tiết hiện tại, không phát sinh chi phí phát triển thêm. Thời gian hoàn vốn 6–12 tháng nhờ tiết kiệm đáng kể thời gian thao tác thủ công.\n3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS Serverless để quản lý dữ liệu từ 5 trạm dựa trên Raspberry Pi, có thể mở rộng lên 15 trạm. Dữ liệu được tiếp nhận qua AWS IoT Core, lưu trữ trong S3 data lake và xử lý bởi AWS Glue Crawlers và ETL jobs để chuyển đổi và tải vào một S3 bucket khác cho mục đích phân tích. Lambda và API Gateway xử lý bổ sung, trong khi Amplify với Next.js cung cấp bảng điều khiển được bảo mật bởi Cognito.\nDịch vụ AWS sử dụng\nAWS IoT Core: Tiếp nhận dữ liệu MQTT từ 5 trạm, mở rộng lên 15. AWS Lambda: Xử lý dữ liệu và kích hoạt Glue jobs (2 hàm). Amazon API Gateway: Giao tiếp với ứng dụng web. Amazon S3: Lưu trữ dữ liệu thô (data lake) và dữ liệu đã xử lý (2 bucket). AWS Glue: Crawlers lập chỉ mục dữ liệu, ETL jobs chuyển đổi và tải dữ liệu. AWS Amplify: Lưu trữ giao diện web Next.js. Amazon Cognito: Quản lý quyền truy cập cho người dùng phòng lab. Thiết kế thành phần\nThiết bị biên: Raspberry Pi thu thập và lọc dữ liệu cảm biến, gửi tới IoT Core. Tiếp nhận dữ liệu: AWS IoT Core nhận tin nhắn MQTT từ thiết bị biên. Lưu trữ dữ liệu: Dữ liệu thô lưu trong S3 data lake; dữ liệu đã xử lý lưu ở một S3 bucket khác. Xử lý dữ liệu: AWS Glue Crawlers lập chỉ mục dữ liệu; ETL jobs chuyển đổi để phân tích. Giao diện web: AWS Amplify lưu trữ ứng dụng Next.js cho bảng điều khiển và phân tích thời gian thực. Quản lý người dùng: Amazon Cognito giới hạn 5 tài khoản hoạt động. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm 2 phần — thiết lập trạm thời tiết biên và xây dựng nền tảng thời tiết — mỗi phần trải qua 4 giai đoạn:\nNghiên cứu và vẽ kiến trúc: Nghiên cứu Raspberry Pi với cảm biến ESP32 và thiết kế kiến trúc AWS Serverless (1 tháng trước kỳ thực tập). Tính toán chi phí và kiểm tra tính khả thi: Sử dụng AWS Pricing Calculator để ước tính và điều chỉnh (Tháng 1). Điều chỉnh kiến trúc để tối ưu chi phí/giải pháp: Tinh chỉnh (ví dụ tối ưu Lambda với Next.js) để đảm bảo hiệu quả (Tháng 2). Phát triển, kiểm thử, triển khai: Lập trình Raspberry Pi, AWS services với CDK/SDK và ứng dụng Next.js, sau đó kiểm thử và đưa vào vận hành (Tháng 2–3). Yêu cầu kỹ thuật\nTrạm thời tiết biên: Cảm biến (nhiệt độ, độ ẩm, lượng mưa, tốc độ gió), vi điều khiển ESP32, Raspberry Pi làm thiết bị biên. Raspberry Pi chạy Raspbian, sử dụng Docker để lọc dữ liệu và gửi 1 MB/ngày/trạm qua MQTT qua Wi-Fi. Nền tảng thời tiết: Kiến thức thực tế về AWS Amplify (lưu trữ Next.js), Lambda (giảm thiểu do Next.js xử lý), AWS Glue (ETL), S3 (2 bucket), IoT Core (gateway và rules), và Cognito (5 người dùng). Sử dụng AWS CDK/SDK để lập trình (ví dụ IoT Core rules tới S3). Next.js giúp giảm tải Lambda cho ứng dụng web fullstack. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch và đánh giá trạm cũ. Thực tập (Tháng 1–3): Tháng 1: Học AWS và nâng cấp phần cứng. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Nghiên cứu thêm trong vòng 1 năm. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nAWS Lambda: 0,00 USD/tháng (1.000 request, 512 MB lưu trữ). S3 Standard: 0,15 USD/tháng (6 GB, 2.100 request, 1 GB quét). Truyền dữ liệu: 0,02 USD/tháng (1 GB vào, 1 GB ra). AWS Amplify: 0,35 USD/tháng (256 MB, request 500 ms). Amazon API Gateway: 0,01 USD/tháng (2.000 request). AWS Glue ETL Jobs: 0,02 USD/tháng (2 DPU). AWS Glue Crawlers: 0,07 USD/tháng (1 crawler). MQTT (IoT Core): 0,08 USD/tháng (5 thiết bị, 45.000 tin nhắn). Tổng: 0,7 USD/tháng, 8,40 USD/12 tháng\nPhần cứng: 265 USD một lần (Raspberry Pi 5 và cảm biến). 7. Đánh giá rủi ro Ma trận rủi ro\nMất mạng: Ảnh hưởng trung bình, xác suất trung bình. Hỏng cảm biến: Ảnh hưởng cao, xác suất thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nMạng: Lưu trữ cục bộ trên Raspberry Pi với Docker. Cảm biến: Kiểm tra định kỳ, dự phòng linh kiện. Chi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Dữ liệu và phân tích thời gian thực thay thế quy trình thủ công. Có thể mở rộng tới 10–15 trạm.\nGiá trị dài hạn: Nền tảng dữ liệu 1 năm cho nghiên cứu AI, có thể tái sử dụng cho các dự án tương lai.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/","title":"Kiểm tra Gateway Endpoint","tags":[],"description":"","content":"Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/","title":"Tạo một S3 Interface endpoint","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.3-week3/","title":"Nhật ký Tuần 3","tags":[],"description":"","content":"Mục tiêu Tuần 3: Hoàn thành Module 03: Amazon EC2 (Phần 1) Hiểu các loại instance EC2 và tùy chọn mua Tìm hiểu về các tính năng lưu trữ và mạng của EC2 Công việc cần thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Học Module 03-01-01: Tổng quan EC2 - Các loại instance EC2 - Các khái niệm Hypervisor 22/09/2025 22/09/2025 AWS Cloud Journey 2 - Học Module 03-01-02: AMI \u0026amp; Key Pairs - Amazon Machine Images - Quản lý Key Pair 23/09/2025 23/09/2025 AWS Cloud Journey 3 - Học Module 03-01-03: EBS - Elastic Block Store - Các loại HDD vs SSD 24/09/2025 24/09/2025 AWS Cloud Journey 4 - Học Module 03-01-04: Instance Store - Instance Store vs EBS - Các trường hợp sử dụng 25/09/2025 25/09/2025 AWS Cloud Journey 5 - Thực hành Lab: Module 03-Lab01 - Launch EC2 instances - Cấu hình storage 26/09/2025 26/09/2025 AWS Cloud Journey 6-7 - Tiếp tục Thực hành Lab - Test các loại instance khác nhau - Backup và restore 27-28/09/2025 28/09/2025 AWS Cloud Journey Thành tựu Tuần 3: Hiểu các loại instance EC2 và khi nào sử dụng mỗi loại Học về AMIs để tùy chỉnh EC2 instances Nắm vững Key Pair creation và SSH access Phân biệt được EBS và Instance Store Hiểu về các loại volume EBS và performance Tạo thành công và cấu hình EC2 instances Gắn và cấu hình EBS volumes Tạo AMIs cho mục đích backup Test SSH connectivity sử dụng key pairs Khó khăn đối mặt: Lựa chọn loại instance phù hợp cho workload Hiểu sự khác biệt giữa EBS và Instance Store Cấu hình storage performance phù hợp Giải pháp đã thực hiện: Tạo ma trận quyết định lựa chọn EC2 instance Xây dựng bảng so sánh các tùy chọn lưu trữ Metodology test performance cho EBS volumes Kế hoạch Tuần tới: Tiếp tục Module 03: Amazon EC2 (Phần 2) Học về User Data và Metadata Tìm hiểu về Auto Scaling và Load Balancing "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/","title":"Kiểm tra Interface Endpoint","tags":[],"description":"","content":"Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-s3-vpc/","title":"Truy cập S3 từ VPC","tags":[],"description":"","content":"Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.4-week4/","title":"Nhật ký Tuần 4","tags":[],"description":"","content":"Mục tiêu Tuần 4: Hoàn thành Module 03: Amazon EC2 (Phần 2) Hiểu các tính năng nâng cao của EC2 Tìm hiểu về Auto Scaling và các dịch vụ liên quan Công việc cần thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Học Module 03-01-05: User Data - EC2 User Data scripts - Bootstrap instances 29/09/2025 29/09/2025 AWS Cloud Journey 2 - Học Module 03-01-06: Metadata - EC2 Instance Metadata - Dynamic configuration 30/09/2025 30/09/2025 AWS Cloud Journey 3 - Học Module 03-01-07: Auto Scaling - Auto Scaling Groups - Scaling policies 01/10/2025 01/10/2025 AWS Cloud Journey 4 - Học Module 03-02: Dịch vụ Nâng cao - EFS, FSx, Lightsail - Migration services 02/10/2025 02/10/2025 AWS Cloud Journey 5 - Thực hành Lab: Module 03-Lab13 - Cấu hình Auto Scaling - Test scaling policies 03/10/2025 03/10/2025 AWS Cloud Journey 6-7 - Tiếp tục Thực hành Lab - Làm việc với EFS - Performance testing 04-05/10/2025 05/10/2025 AWS Cloud Journey Thành tựu Tuần 4: Nắm vững EC2 User Data cho instance bootstrap Học sử dụng Instance Metadata để cấu hình động Hiểu về Auto Scaling Groups và policies Kiến thức về EFS cho shared storage giữa instances Tiếp xúc với dịch vụ migration (MGN) Cấu hình thành công Auto Scaling Group Triển khai scaling policies dựa trên metrics Test EFS file system với nhiều EC2 instances Tạo các kịch bản disaster recovery Khó khăn đối mặt: Debug User Data scripts Cấu hình Auto Scaling policies phù hợp Hiểu các đặc điểm performance của EFS Giải pháp đã thực hiện: Tạo templates cho User Data scripts Xây dựng hướng dẫn cấu hình Auto Scaling từng bước Metodology test performance cho EFS Kế hoạch Tuần tới: Bắt đầu Module 04: Dịch vụ lưu trữ AWS Tập trung vào S3 và các lớp lưu trữ Chuẩn bị cho dịch thuật blog vào ngày 10/10 "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/","title":"Mô phỏng On-premises DNS ","tags":[],"description":"","content":"AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/","title":"Truy cập S3 từ môi trường truyền thống","tags":[],"description":"","content":"Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.5-week5/","title":"Nhật ký Tuần 5","tags":[],"description":"","content":"Mục tiêu Tuần 5: Hoàn thành Module 04: Dịch vụ lưu trữ AWS Dịch thuật Blog vào ngày 10 tháng 10 Ôn tập các khái niệm đã học Công việc cần thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Học Module 04-01: Tổng quan Storage - S3, Storage Gateway, Snow Family - Disaster Recovery concepts 06/10/2025 06/10/2025 AWS Cloud Journey 2 - Học Module 04-02: S3 Deep Dive - S3 Buckets, Access Points - Storage Classes - Dịch thuật Blog 07/10/2025 07/10/2025 AWS Cloud Journey 3 - Học Module 04-03: S3 Nâng cao - S3 Static Websites - CORS, Versioning, Glacier - Dịch thuật Blog 08/10/2025 08/10/2025 AWS Cloud Journey 4 - Học Module 04-04: Hybrid Storage - Storage Gateway - Snow Family, AWS Backup - Dịch thuật Blog 09/10/2025 09/10/2025 AWS Cloud Journey 5 NGÀY DỊCH THUẬT BLOG - Dịch thuật nội dung blog được giao - Rà soát và chỉnh sửa bản dịch 10/10/2025 10/10/2025 Dịch thuật Blog 6-7 - Thực hành Lab: Module 04-Lab13 - Thiết lập S3 static website - Cấu hình CloudFront 11-12/10/2025 12/10/2025 AWS Cloud Journey Thành tựu Tuần 5: Hiểu về portfolio dịch vụ lưu trữ AWS Nắm vững các khái niệm S3 và storage classes Kiến thức về S3 static website hosting Hiểu về các giải pháp lưu trữ hybrid Dịch thuật thành công nội dung blog Cấu hình S3 bucket cho static website Thiết lập CloudFront distribution Triển khai CORS policies Test S3 versioning và lifecycle policies Khó khăn đối mặt: Hiểu các transitions S3 storage class Cấu hình CORS policies phù hợp Thuật ngữ kỹ thuật trong dịch thuật blog Giải pháp đã thực hiện: Tạo decision tree cho S3 storage class Xây dựng templates cấu hình CORS Glossary thuật kỹ thuật cho nhất quán dịch thuật Kế hoạch Tuần tới: Bắt đầu Module 05: AWS Security \u0026amp; IAM Học Shared Responsibility Model Tìm hiểu về IAM, Cognito, và Organizations "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.5-policy/","title":"VPC Endpoint Policies","tags":[],"description":"","content":"Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nĐảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.6-week6/","title":"Nhật ký Tuần 6","tags":[],"description":"","content":"Mục tiêu Tuần 6: Hoàn thành Module 05: AWS Security \u0026amp; IAM Ôn tập tất cả khái niệm từ Module 1-5 Nghiên cứu cho dự án cuối kỳ Công việc cần thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Học Module 05-01: Shared Responsibility Model - AWS vs Customer responsibilities - Service model considerations 13/10/2025 13/10/2025 AWS Cloud Journey 2 - Học Module 05-02: IAM Deep Dive - Users, Groups, Roles, Policies - Best practices 14/10/2025 14/10/2025 AWS Cloud Journey 3 - Học Module 05-03: Amazon Cognito - User Pools vs Identity Pools - Federation 15/10/2025 15/10/2025 AWS Cloud Journey 4 - Học Module 05-04: AWS Organizations - Multi-account management - Service Control Policies 16/10/2025 16/10/2025 AWS Cloud Journey 5 - Thực hành Lab: Module 05-Lab18 - AWS Security Hub setup - Security compliance 17/10/2025 17/10/2025 AWS Cloud Journey 6-7 ÔN TẬP \u0026amp; NGHIÊN CỨU - Ôn tập Module 1-5 - Nghiên cứu ý tưởng dự án cuối kỳ 18-19/10/2025 19/10/2025 Tài liệu học Thành tựu Tuần 6: Hiểu AWS Shared Responsibility Model Nắm vững IAM concepts và best practices Kiến thức về Cognito cho user authentication Hiểu về multi-account management với Organizations Cấu hình thành công Security Hub Ôn tập toàn diện Module 1-5 Nghiên cứu các kiến trúc dự án tiềm năng Tạo ghi chú học tập để chuẩn bị thi Xây dựng nền tảng cho nghiên cứu dự án Khó khăn đối mặt: Hiểu IAM policy evaluation logic Phân biệt Cognito User Pool vs Identity Pool Lựa chọn phạm vi phù hợp cho dự án cuối kỳ Giải pháp đã thực hiện: Tạo flowchart quyết định IAM policy Xây dựng bảng so sánh các tính năng Cognito Tài liệu hóa yêu cầu và ràng buộc dự án Kế hoạch Tuần tới: Bắt đầu Module 06: AWS Database Services Học RDS, Aurora, và DynamoDB Tiếp tục nghiên cứu dự án cuối kỳ "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.6-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng [liệt kê kỹ năng: lập trình, phân tích, viết báo cáo, giao tiếp…].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.7-week7/","title":"Nhật ký Tuần 7","tags":[],"description":"","content":"Mục tiêu Tuần 7: Hoàn thành Module 06: AWS Database Services Hiểu các khái niệm database và các dịch vụ database của AWS Tiếp tục nghiên cứu dự án cuối kỳ Công việc cần thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Học Module 06-01: Database Concepts - SQL vs NoSQL - OLTP vs OLAP 20/10/2025 20/10/2025 AWS Cloud Journey 2 - Học Module 06-02: RDS \u0026amp; Aurora - Amazon RDS features - Aurora advantages 21/10/2025 21/10/2025 AWS Cloud Journey 3 - Học Module 06-03: Redshift \u0026amp; ElastiCache - Data warehousing - Caching strategies 22/10/2025 22/10/2025 AWS Cloud Journey 4 - Thực hành Lab: Module 06-Lab05 - Create RDS instance - Configure backup 23/10/2025 23/10/2025 AWS Cloud Journey 5 - Thực hành Lab tiếp theo - Connect EC2 to RDS - Test failover 24/10/2025 24/10/2025 AWS Cloud Journey 6-7 NGHIÊN CỨU DỰ ÁN - Thiết kế kiến trúc dự án - Tạo kế hoạch dự án 25-26/10/2025 26/10/2025 Nguồn dự án Thành tựu Tuần 7: Hiểu các khái niệm database fundamentals Kiến thức về AWS RDS và Aurora features Hiểu về data warehousing với Redshift Kiến thức về caching với ElastiCache Tạo thành công và cấu hình RDS instance Triển khai backup và restore procedures Thiết kế kiến trúc dự án Tạo kế hoạch triển khai chi tiết Khó khăn đối mặt: Lựa chọn giữa các loại database engine khác nhau Hiểu Multi-AZ configurations Thiết kế kiến trúc dự án có khả năng mở rộng Giải pháp đã thực hiện: Tạo ma trận quyết định lựa chọn database Xây dựng checklist cấu hình RDS Tài liệu hóa kiến trúc dự án với sơ đồ Kế hoạch Tuần tới: Bắt đầu Module 07: Data Analytics \u0026amp; Lake House Học Glue, Athena, và QuickSight Bắt đầu triển khai dự án cuối kỳ "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.8-week8/","title":"Nhật ký Tuần 8","tags":[],"description":"","content":"Mục tiêu Tuần 8: Hoàn thành Module 07: Data Analytics \u0026amp; Lake House Hiểu các khái niệm data lake và services Bắt đầu triển khai dự án cuối kỳ Công việc cần thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Học Data Lake Concepts - Glue, Athena, QuickSight overview - Data pipeline architecture 27/10/2025 27/10/2025 AWS Cloud Journey 2 - Học Module 07-01: DynamoDB - NoSQL concepts - DynamoDB features 28/10/2025 28/10/2025 AWS Cloud Journey 3 - Thực hành Lab: Module 07-Lab35 - Create S3 Data Lake - Set up Glue Crawler 29/10/2025 29/10/2025 AWS Cloud Journey 4 - Thực hành Lab tiếp theo - Athena queries - QuickSight visualization 30/10/2025 30/10/2025 AWS Cloud Journey 5 TRIỂN KHAI DỰ ÁN CUỐI KỲ - Thiết lập cơ sở hạ tầng dự án - Cấu hình các dịch vụ cốt lõi 31/10/2025 31/10/2025 Nguồn dự án 6-7 LÀM VIỆC DỰ ÁN - Triển khai các tính năng chính - Test functionality 01-02/11/2025 02/11/2025 Nguồn dự án Thành tựu Tuần 8: Hiểu về kiến trúc Data Lake Kiến thức về AWS Analytics services Kinh nghiệm thực hành với Glue, Athena, QuickSight Hiểu về DynamoDB NoSQL database Tạo thành công Data Lake pipeline Triển khai data catalog với Glue Tạo visualizations với QuickSight Bắt đầu triển khai dự án cuối kỳ Khó khăn đối mặt: Hiểu Data Lake vs Data Warehouse Cấu hình IAM phù hợp cho analytics services Debug data transformations Giải pháp đã thực hiện: Tạo sơ đồ kiến trúc Data Lake Xây dựng IAM policy templates cho analytics Hướng dẫn data pipeline từng bước Kế hoạch Tuần tới: Hoàn thành triển khai dự án cuối kỳ Tài liệu hóa kiến trúc dự án Chuẩn bị cho thuyết trình "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.9-week9/","title":"Nhật ký Tuần 9","tags":[],"description":"","content":"Mục tiêu Tuần 9: Nghiên cứu AWS Advanced Services cho Dự án Cuối kỳ Deep dive vào security, CI/CD, và infrastructure services Đánh giá các công cụ để triển khai dự án Công việc cần thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 Amazon Cognito Deep Dive - User pools vs Identity pools - Authentication flows - Social integration 03/11/2025 03/11/2025 AWS Docs 2 AWS WAF \u0026amp; Security - WAF rules và ACLs - Security best practices - DDoS protection 04/11/2025 04/11/2025 AWS Docs 3 Developer Tools Research - CodeCommit, CodeBuild, CodePipeline - CodeStar overview - CI/CD workflows 05/11/2025 05/11/2025 AWS Docs 4 Infrastructure as Code - Terraform fundamentals - CloudFormation vs Terraform - IaC best practices 06/11/2025 06/11/2025 Terraform Docs 5 AWS Amplify \u0026amp; Lambda - Amplify framework - Lambda deep dive - Serverless patterns 07/11/2025 07/11/2025 AWS Docs 6-7 Global Services - Route 53 configuration - CloudFront strategies - S3 advanced patterns 08-09/11/2025 09/11/2025 AWS Docs Thành tựu Tuần 9: Hiểu toàn diện về các pattern authentication Cognito Kiến thức về cấu hình WAF cho bảo mật web application Hiểu về các thành phần CI/CD pipeline của AWS Thành thạo cơ bản Terraform cho infrastructure management Nhận biết về các khả năng của Amplify cho phát triển full-stack Kiến thức về Route 53 cho DNS management Hiểu về các chiến lược tối ưu CloudFront Các pattern S3 nâng cao cho các use cases khác nhau Khó khăn đối mặt: Độ phức tạp của cấu hình Cognito Đường cong học Terraform Quyết định thiết kế CI/CD pipeline Giải pháp đã thực hiện: Tạo templates cấu hình Cognito Xây dựng ví dụ modules Terraform Thiết kế sample CI/CD workflows Tài liệu hóa các quy tắc WAF Kế hoạch Tuần tới: Thiết kế kiến trúc dự án cuối kỳ Tạo kế hoạch triển khai chi tiết Thiết lập môi trường phát triển "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.10-week10/","title":"Nhật ký Tuần 10","tags":[],"description":"","content":"Mục tiêu Tuần 10: Thiết kế Kiến trúc Dự án Cuối kỳ Lập kế hoạch triển khai infrastructure Tạo thông số kỹ thuật chi tiết Công việc cần thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 Architecture Planning - Thiết kế hệ thống kiến trúc - Định nghĩa cấu trúc microservices - Tạo sơ đồ luồng dữ liệu 10/11/2025 10/11/2025 Architecture Docs 2 Infrastructure Design - Lập kế VPC architecture - Thiết kế lớp security - Lập kế CI/CD pipeline 11/11/2025 11/11/2025 AWS Well-Architected 3 Database Architecture - Thiết kế data models - Lập kế RDS/DynamoDB usage - Thiết kế caching strategy 12/11/2025 12/11/2025 Database Patterns 4 Security Architecture - Thiết kế authentication flow với Cognito - Lập kế WAF rules - Thiết kế IAM structure 13/11/2025 13/11/2025 Security Best Practices 5 CDN \u0026amp; Global Design - Lập kế CloudFront distribution - Thiết kế Route 53 strategy - Lập kế S3 bucket structure 14/11/2025 14/11/2025 AWS Patterns 6-7 Create Terraform Scripts - Viết infrastructure code - Tạo modular design - Lập kế deployment stages 15-16/11/2025 16/11/2025 Terraform Thành tựu Tuần 10: Tài liệu hóa kiến trúc hệ thống hoàn chỉnh Thiết kế infrastructure chi tiết với các cân nhắc security Kế hoạch kiến trúc data toàn diện Scripts Terraform để triển khai infrastructure Thiết kế CI/CD pipeline sử dụng AWS CodePipeline Kiến trúc security với WAF và Cognito integration Chiến lược triển khai toàn cầu với CloudFront và Route 53 Infrastructure code modular để tái sử dụng Khó khăn đối mặt: Cân bằng độ phức tạp vs khả năng mở rộng Trade-offs giữa security và accessibility Tối ưu hóa chi phí trong thiết kế Giải pháp đã thực hiện: Tạo architecture decision records (ADRs) Xây dựng mô hình ước tính chi phí Thiết kế phương pháp triển khai theo giai đoạn Tạo chiến lược testing infrastructure Kế hoạch Tuần tới: Bắt đầu coding backend services Triển khai core infrastructure với Terraform Thiết lập CI/CD pipeline "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.11-week11/","title":"Nhật ký Tuần 11","tags":[],"description":"","content":"Mục tiêu Tuần 11: Phát triển Backend Services Triển khai Lambda Function Thiết lập CI/CD Pipeline Công việc cần thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 Infrastructure Deployment - Áp dụng Terraform scripts - Thiết lập VPC và security groups - Cấu hình S3 buckets 17/11/2025 17/11/2025 Terraform 2 Database Setup - Triển khai RDS instances - Cấu hình DynamoDB tables - Thiết lập ElastiCache 18/11/2025 18/11/2025 AWS Console 3 Lambda Development - Tạo Lambda functions - Triển khai API endpoints - Thiết lập API Gateway 19/11/2025 19/11/2025 VS Code 4 Cognito Integration - Thiết lập User Pool - Cấu hình authentication - Triển khai auth trong Lambda 20/11/2025 20/11/2025 AWS Console 5 CodeCommit Setup - Khởi tạo repositories - Push code ban đầu - Thiết lập branch strategy 21/11/2025 21/11/2025 Git 6-7 CI/CD Pipeline - Cấu hình CodeBuild - Thiết lập CodePipeline - Test automated deployments 22-23/11/2025 23/11/2025 AWS Code* Thành tựu Tuần 11: Triển khai thành công infrastructure sử dụng Terraform Cấu hình hoàn toàn database layer với RDS và DynamoDB Triển khai backend services với Lambda Tích hợp hệ thống authentication Cognito Thiết lập version control với CodeCommit Xây dựng CI/CD pipeline với automated deployments Tạo Lambda functions modular cho các dịch vụ khác nhau Triển khai error handling và logging phù hợp Khó khăn đối mặt: Quản lý state Terraform Tối ưu hóa cold start Lambda Debug CI/CD pipeline Độ phức tạp của cấu hình Cognito Giải pháp đã thực hiện: Sử dụng remote state storage cho Terraform Triển khai Lambda best practices cho performance Tạo pipeline testing strategies Xây dựng templates cấu hình Cognito Kế hoạch Tuần tới: Phát triển frontend với Amplify Testing và bảo đảm chất lượng Tối ưu hóa performance Tài liệu hóa và deployment "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.12-week12/","title":"Nhật ký Tuần 12","tags":[],"description":"","content":"Mục tiêu Tuần 12: Phát triển Frontend với Amplify Testing và Quality Assurance Tối ưu hóa Performance và Deployment Công việc cần thực hiện trong tuần: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 Amplify Setup - Khởi tạo dự án Amplify - Cấu hình auth với Cognito - Thiết lập GraphQL API 24/11/2025 24/11/2025 Amplify Docs 2 Frontend Development - Xây dựng React/Vue components - Tích hợp với API Gateway - Triển khai authentication flow 25/11/2025 25/11/2025 React/Vue 3 CloudFront \u0026amp; Route 53 - Cấu hình CloudFront distribution - Thiết lập custom domain - Cấu hình Route 53 26/11/2025 26/11/2025 AWS Console 4 WAF Implementation - Thiết lập WAF rules - Cấu hình SQL injection protection - Thiết lập rate limiting 27/11/2025 27/11/2025 AWS WAF 5 Testing \u0026amp; QA - Unit testing - Integration testing - Load testing 28/11/2025 28/11/2025 Testing Tools 6-7 Final Deployment - Production deployment - Thiết lập monitoring - Hoàn thành tài liệu 29-30/11/2025 30/11/2025 AWS Thành tựu Tuần 12: Triển khai thành công ứng dụng full-stack với Amplify Tích hợp authentication với Cognito Cấu hình global CDN với CloudFront Thiết lập custom domain với Route 53 Triển khai WAF cho bảo mật Hoàn thành testing toàn diện Tối ưu hóa performance ứng dụng Triển khai đến production environment Tạo tài liệu dự án hoàn chỉnh Khó khăn đối mặt: Độ phức tạp của cấu hình Amplify Tích hợp frontend-backend Delays truyền DNS Tối ưu hóa performance Giải pháp đã thực hiện: Sử dụng Amplify CLI cho thiết lập streamlined Tạo layer tích hợp API Lập kế thay đổi DNS trước Triển khai caching strategies Tóm tắt Dự án: Xây dựng ứng dụng serverless hoàn chỉnh Sử dụng các dịch vụ AWS hiện đại (Lambda, DynamoDB, Cognito) Triển khai CI/CD với AWS CodePipeline Đạt được khả năng mở rộng toàn cầu với CloudFront Bảo mật ứng dụng với WAF Tài liệu hóa toàn bộ kiến trúc và quy trình deployment "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.1-blog1/","title":"","tags":[],"description":"","content":"Cách AWS và Intel giúp các mô hình ngôn ngữ lớn trở nên dễ tiếp cận và tiết kiệm chi phí hơn với DeepSeek bởi Dylan Souvage, Vishwa Gopinath Kurakundi, và Anish Kumar vào 07 THÁNG 4 2025 trong Amazon EC2, Artificial Intelligence, Compute, Generative AI, Generative AI, Partner solutions, Responsible AI Permalink\nBởi Anish Kumar, Quản lý kỹ thuật phần mềm AI – Intel\nDylan Souvage, Kiến trúc sư giải pháp – AWS\nVishwa Gopinath Kurakundi, Kiến trúc sư giải pháp – AWS\nDoanh nghiệp đang tìm kiếm các cách triển khai Mô hình ngôn ngữ lớn (LLM) hiệu quả. Họ muốn tận dụng sức mạnh của LLM nhưng đồng thời cần những giải pháp cân bằng giữa hiệu năng và chi phí.\nTại hội nghị AWS re:Invent gần đây ở Las Vegas, Andy Jassy, Giám đốc điều hành của Amazon, đã chia sẻ ba bài học quý giá rút ra từ kinh nghiệm nội bộ của Amazon khi xây dựng hơn 1.000 ứng dụng GenAI:\nHiệu quả chi phí ở quy mô lớn là yếu tố then chốt đối với các ứng dụng GenAI. Xây dựng ứng dụng GenAI hiệu quả đòi hỏi sự cân nhắc kỹ lưỡng. Đa dạng mô hình là điều thiết yếu – không có giải pháp “một mô hình cho tất cả”. Những bài học này định hướng cho cách AWS hợp tác cùng khách hàng để triển khai GenAI. Tại AWS, chúng tôi nhận thấy tính linh hoạt và quyền lựa chọn là điều quan trọng đối với khách hàng. Andy Jassy cũng nhấn mạnh rằng danh mục LLM đa dạng của AWS giúp khách hàng dễ dàng tìm được công cụ phù hợp cho nhu cầu riêng. Nhờ sự hợp tác sâu rộng với các đối tác như Intel, AWS liên tục mở rộng danh mục LLM được tuyển chọn, tăng cường khả năng tiếp cận cho khách hàng.\nIntel và AWS Sự hợp tác giữa AWS và Intel bắt đầu từ năm 2006, khi chúng tôi ra mắt Amazon Elastic Compute Cloud (EC2) sử dụng chip của Intel. Trải qua 19 năm, quan hệ hợp tác này đã phát triển mạnh mẽ nhằm cung cấp các dịch vụ đám mây giúp tối ưu chi phí, đơn giản hóa vận hành và đáp ứng nhu cầu doanh nghiệp đang thay đổi. Các bộ xử lý Intel® Xeon® Scalable là nền tảng cho nhiều dịch vụ điện toán đám mây trên AWS. Các phiên bản EC2 sử dụng bộ xử lý Intel Xeon có độ phủ lớn nhất, phạm vi toàn cầu và khả năng sẵn sàng cao nhất trong các khu vực AWS. Vào tháng 9 năm 2024, AWS và Intel công bố một thỏa thuận đầu tư chung kéo dài nhiều năm, trị giá hàng tỷ đô, nhằm thiết kế chip tùy chỉnh bao gồm cả sản phẩm và wafer từ Intel. Đây là bước mở rộng hợp tác lâu dài giữa hai công ty, giúp khách hàng vận hành hầu như mọi loại khối lượng công việc và tăng tốc hiệu năng của ứng dụng trí tuệ nhân tạo (AI).\nDeepSeek AWS và Intel đang hợp tác để giúp các doanh nghiệp tiếp cận và triển khai LLM hiệu quả hơn về chi phí. Một xu hướng mới là mô hình ngôn ngữ chưng cất, chúng vẫn giữ được hiệu năng cao nhưng yêu cầu ít tài nguyên hơn. Những mô hình này có thể chạy trực tiếp trên CPU, còn được gọi là Mô hình ngôn ngữ nhỏ (SLM – Small Language Models). Việc huấn luyện và suy luận SLM trên CPU giúp triển khai AI hiệu năng cao trong giới hạn thời gian và chi phí hợp lý. Các mô hình DeepSeek (đơn vị phát triển DeepSeek-R1) đang nhanh chóng trở nên phổ biến nhờ hiệu quả, chi phí thấp và mã nguồn mở, cho phép triển khai tự do trong ứng dụng. Ngoài ra, DeepSeek còn cung cấp phiên bản chưng cất, các mô hình “học sinh” nhỏ hơn, được huấn luyện để tái tạo chất lượng phản hồi của mô hình “giáo viên” lớn hơn nhưng tiêu tốn ít tài nguyên hơn.\nAmazon EC2 là một nền tảng tiết kiệm chi phí để triển khai các Mô hình Ngôn ngữ Lớn (LLM), đồng thời cung cấp các loại máy chủ chuyên dụng chạy trên bộ xử lý Intel® Xeon® Scalable, phù hợp để triển khai các mô hình đã được tối ưu hóa như DeepSeek-R1 phiên bản chưng cất. Các CPU Intel® Xeon® Thế hệ thứ 4 trở lên được trang bị bộ tăng tốc Advanced Matrix Extensions (AMX), giúp tăng đáng kể hiệu năng xử lý khối lượng công việc của LLM bằng cách tăng tốc các phép nhân ma trận, một thành phần cốt lõi trong quá trình suy luận của LLM. Các bộ tăng tốc AMX này mang lại hiệu suất xử lý vượt trội, đồng thời tích hợp với các tiêu chuẩn mở như oneAPI, giúp doanh nghiệp triển khai các ứng dụng Trí tuệ Nhân tạo Sinh tạo (Generative AI) với chi phí hợp lý, khả năng mở rộng cao, thời gian thu nhận kết quả nhanh hơn và tổng chi phí sở hữu (TCO) thấp hơn.\nAmazon EC2 cũng mang lại sự linh hoạt và khả năng mở rộng tuyệt vời khi hỗ trợ nhiều cấu hình triển khai khác nhau, bao gồm cả mô hình LLM ảo (vLLM) có thể tích hợp liền mạch với Docker dựa trên nền tảng Hugging Face. Trong bài viết hướng dẫn đi kèm này, chúng ta sẽ cùng xem chi tiết từng bước cách triển khai nhanh mô hình DeepSeek-R1-Distill-Llama-8B trên máy chủ Amazon EC2 m7i.2xlarge, sử dụng bộ xử lý Intel® Xeon® Scalable với 8 vCPU và 32 GB bộ nhớ. Bài viết cung cấp hướng dẫn chi tiết về cách cấu hình Amazon EC2 để triển khai mô hình, đồng thời xây dựng container Docker cho vLLM trên CPU – bao gồm các tối ưu hóa của Intel dành cho CPU như Intel Extension for PyTorch. Tiện ích mở rộng này đảm bảo các quá trình suy luận của LLM được tối ưu để chạy hiệu quả trên các bộ xử lý Intel® Xeon® Thế hệ thứ 4 trở lên, và bài viết kết thúc bằng phần kiểm thử quá trình suy luận sau khi mô hình được triển khai.\nKết luận Doanh nghiệp có thể triển khai các LLM tùy chỉnh hoặc mã nguồn mở, bao gồm Distilled DeepSeek-R1, trên AWS thông qua các dịch vụ được quản lý như Amazon Bedrock và Amazon SageMaker, hoặc triển khai trực tiếp trên Amazon EC2, tùy theo nhu cầu cụ thể. Sự hợp tác giữa AWS và Intel đang thúc đẩy sự phát triển của lĩnh vực Trí tuệ Nhân tạo Sinh tạo, kết hợp công nghệ bán dẫn tiên tiến của Intel với hạ tầng đám mây mạnh mẽ của AWS để mang lại các giải pháp AI dễ tiếp cận và tiết kiệm chi phí.\nĐể tìm hiểu thêm về lĩnh vực Generative AI của AWS, hãy truy cập blog Machine Learning của AWS.\nIntel – AWS Partner Spotlight Intel và Amazon Web Services (AWS) đã hợp tác hơn 19 năm để phát triển các công nghệ linh hoạt và tối ưu phần mềm, phục vụ cho các khối lượng công việc quan trọng của doanh nghiệp. Sự hợp tác này cho phép các đối tác AWS hỗ trợ khách hàng di chuyển và hiện đại hóa ứng dụng cũng như hạ tầng của họ – giúp giảm chi phí và độ phức tạp, đẩy nhanh kết quả kinh doanh, đồng thời mở rộng quy mô để đáp ứng các nhu cầu tính toán hiện tại và tương lai.\nLiên hệ Intel | Tổng quan đối tác | AWS Marketplace\nTAGS: Amazon EC2, AWS Competency Partners, AWS Partner Solution, Generative AI, Intel\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.2-blog2/","title":"","tags":[],"description":"","content":"Cách AWS Skill Builder thúc đẩy tăng trưởng kỹ năng số tại các tổ chức châu Âu bởi Luigi Belli và Aleksandar Borisavljević vào 10 THÁNG 4 2025 trong Announcements, Artificial Intelligence, Education, Europe, Generative AI, Government, Public Sector, Regions Permalink\nKhi các cơ quan châu Âu đang chạy đua để đạt được các mục tiêu chuyển đổi số đầy tham vọng giai đoạn 2024–2029, việc phát triển kỹ năng cho lực lượng lao động đã trở thành yếu tố then chốt. AWS đang giải quyết thách thức này một cách trực diện với các giải pháp học tập chuyên biệt, được thiết kế dành riêng cho các chuyên gia trong khu vực công của Liên minh châu Âu (EU). Trong bài viết này, chúng ta sẽ tìm hiểu cách AWS Skill Builder đang góp phần tạo nên lực lượng lao động có kỹ năng số mà châu Âu đang cần.\nCùng phát triển kỹ năng điện toán đám mây: Sự hỗ trợ chuyên biệt của AWS cho chuyển đổi số khu vực công EU Tại AWS, chúng tôi hiểu rằng chuyển đổi số trong các cơ quan EU không chỉ là vấn đề công nghệ – mà còn đòi hỏi sự thấu hiểu sâu sắc về những thách thức riêng của khu vực công và các yêu cầu pháp lý. Vì vậy, AWS đã thành lập đội ngũ Học tập khu vực công EU chuyên trách, gồm các chuyên gia làm việc trực tiếp với các cơ quan chính phủ châu Âu để đáp ứng nhu cầu phát triển kỹ năng điện toán đám mây của họ. Đội ngũ này được hình thành từ sự hợp tác sâu rộng với các tổ chức như Ủy ban châu Âu, học hỏi trực tiếp từ các chuyên gia EU về yêu cầu và khó khăn trong việc học tập và phát triển kỹ năng.\nCác cơ quan chính phủ EU hoạt động khác biệt so với các tổ chức thương mại hoặc khu vực công ở các nơi khác trên thế giới. Họ phải tuân thủ các quy định nghiêm ngặt như Quy định bảo vệ dữ liệu chung (GDPR), đảm bảo chủ quyền dữ liệu trong phạm vi EU, tuân theo quy tắc đấu thầu công chặt chẽ, và duy trì tiêu chuẩn cao nhất về bảo vệ dữ liệu công dân. Các tài liệu đào tạo điện toán đám mây thông thường, vốn được thiết kế cho đối tượng thương mại toàn cầu, không phải lúc nào cũng đáp ứng được những yêu cầu đặc thù của khu vực công châu Âu. Chính vì vậy, AWS đã phát triển các lộ trình học tập được tùy chỉnh riêng cho các chuyên gia chính phủ EU, đảm bảo mọi khái niệm được giảng dạy đều phù hợp trực tiếp với môi trường pháp lý và trách nhiệm của họ.\nDẫn đầu trong phát triển kỹ năng số cho chính phủ EU Gần đây, AWS đã ra mắt bộ chương trình học trực tuyến chuyên biệt trên AWS Skill Builder—trung tâm học tập kỹ thuật số hàng đầu của chúng tôi – được thiết kế riêng cho các tổ chức EU. Lộ trình học “Kế hoạch học AI sinh tạo cho các chính phủ EU” đã giúp hơn 5.500 chuyên gia trang bị kỹ năng AI cơ bản, thể hiện rõ sự nhiệt huyết ngày càng tăng đối với chuyển đổi số trong khu vực công.\nDựa trên thành công đó, AWS đã tạo ra ba lộ trình học bổ sung:\nKiến thức cơ bản về điện toán đám mây dành cho các nhà lãnh đạo trong chính phủ EU: Dành cho các nhà lãnh đạo và người ra quyết định cấp cao trong chính phủ, cung cấp cái nhìn chiến lược về điện toán đám mây, bao gồm lợi ích, thách thức và các vấn đề quản trị khi áp dụng công nghệ này. Kiến thức kỹ thuật nền tảng cho các dự án của chính phủ EU: Dành cho các lãnh đạo kỹ thuật và kiến trúc sư hệ thống, cung cấp kiến thức nền tảng về điện toán đám mây cần thiết để dẫn dắt thiết kế, triển khai và vận hành các giải pháp đám mây cho các dự án chính phủ. Thiết kế kiến trúc điện toán đám mây cho các cơ quan chính phủ EU: Lộ trình học chuyên biệt cho các kiến trúc sư CNTT và kiến trúc sư doanh nghiệp, tập trung vào thiết kế môi trường đám mây mở rộng, an toàn và tuân thủ quy định cho các tổ chức chính phủ EU. Những chương trình học sáng tạo này được thiết kế phù hợp hoàn toàn với các khung pháp lý của châu Âu và EU Skills Compass, tạo nên những con đường rõ ràng hướng tới sự xuất sắc trong chuyển đổi số.\nAWS Learning System for European Union Institutions \u0026amp; Agencies | AWS Public Sector\nCông bố các buổi Cloud Coach dành cho các chính phủ EU AWS Cloud Coach là một chương trình hoàn toàn miễn phí gồm các sự kiện học tập trực tiếp, giúp thúc đẩy cơ hội học tập ngắn gọn thông qua nền tảng AWS Skill Builder. Khi khách hàng ngày càng áp dụng rộng rãi AWS Skill Builder, chương trình Đào tạo \u0026amp; Chứng nhận AWS mong muốn hỗ trợ hình thức học trực tiếp linh hoạt theo mô hình một-đến-nhiều, mang lại cho người học nhiều lựa chọn và hướng dẫn họ đến những tài nguyên học tập thiết yếu để tiếp tục nâng cao kỹ năng trong môi trường đám mây AWS.\nAWS tự hào công bố Chương trình huấn luyện điện toán đám mây AWS dành cho các tổ chức châu Âu—một loạt hội thảo trực tuyến (webinar) tương tác mới, giúp việc học tập của các chính phủ EU đạt đến tầm cao mới. Trong các buổi học này, những huấn luyện viên kỹ thuật và chứng nhận AWS giàu kinh nghiệm sẽ hướng dẫn người tham gia thông qua các nội dung được chọn lọc từ AWS Skill Builder, đồng thời giải thích cụ thể các tình huống thực tế và yêu cầu tuân thủ trong khu vực công EU. Mỗi buổi Cloud Coach là một cơ hội đặc biệt để đặt câu hỏi trực tiếp, thảo luận về các thách thức trong triển khai thực tế và học hỏi trực tiếp từ các chuyên gia hiểu rõ những đặc thù của việc áp dụng điện toán đám mây trong các cơ quan EU. Người tham gia có thể mong đợi những buổi thảo luận tập trung vào các chủ đề từ khái niệm nền tảng về điện toán đám mây đến các quyết định kiến trúc nâng cao, luôn trong bối cảnh của khung pháp lý và yêu cầu bảo vệ dữ liệu của EU.\nCác buổi học này mang đến một hành trình toàn diện qua những chủ đề cốt lõi về điện toán đám mây — từ kiến thức nền tảng dành cho các nhà lãnh đạo đến các yếu tố kiến trúc nâng cao, bao gồm cả những ứng dụng AI sinh tạo tiên tiến nhất. Dựa trên những hợp tác thành công trước đây với các cơ quan châu Âu, nội dung được tuyển chọn kỹ lưỡng để đáp ứng nhu cầu cụ thể của nhiều vai trò khác nhau trong EU, bao gồm quản lý dự án, nhà phân tích, lập trình viên và kiến trúc sư.\nMặc dù chương trình Cloud Coach chủ yếu hướng đến việc hỗ trợ những khách hàng hiện đang sử dụng Skill Builder Team Subscription, các buổi học này cũng phù hợp với người học cá nhân, khách hàng chưa dùng Skill Builder, và bất kỳ ai quan tâm đến việc tận dụng tối đa các cơ hội học tập mà AWS cung cấp, đồng thời trải nghiệm các buổi học trực tiếp do giảng viên hướng dẫn.\nKết nối với đội ngũ học tập khu vực công EU của chúng tôi Chúng tôi hiểu rằng mỗi cơ quan trong EU đều có nhu cầu học tập và câu hỏi riêng về việc phát triển kỹ năng điện toán đám mây. Đội ngũ Học tập khu vực công EU của AWS sẵn sàng cung cấp các buổi tư vấn không chính thức và miễn phí để thảo luận về yêu cầu cụ thể của tổ chức bạn. Chúng tôi có thể giới thiệu nhiều tài nguyên miễn phí, bao gồm các khóa học số trên AWS Skill Builder, tài liệu chính thức của AWS, phòng lab thực hành, và các lộ trình học tập được thiết kế riêng cho vai trò trong khu vực công EU. Ngoài ra, chúng tôi cũng có thể hướng dẫn về khóa học AWS Cloud Practitioner Essentials, các tài liệu kỹ thuật, và hướng dẫn thực hành tốt nhất phù hợp với yêu cầu của EU.\nĐể biết thêm thông tin về các khóa đào tạo và chứng nhận AWS dành cho các tổ chức chính phủ, hãy truy cập trang chuyên biệt Đào tạo AWS dành cho các cơ quan và tổ chức chính phủ châu Âu.\nTAGS: announcements, Artificial Intelligence, AWS education, AWS for government, AWS Public Sector, region announcement\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.3-blog3/","title":"","tags":[],"description":"","content":"Lưu trữ đồng thời nhiều mô hình ngôn ngữ lớn (LLM) với LoRAX bởi John Kitaoka, Varun Jasti, and Baladithya Balamurugan vào NGÀY 16 THÁNG 4 2025 trong Amazon EC2, Artificial Intelligence, Generative AI, Technical How-to Permalink\nCác doanh nghiệp ngày càng tìm kiếm các mô hình nền tảng (Foundation Models – FMs) được tùy chỉnh theo miền và chuyên biệt để đáp ứng những nhu cầu cụ thể trong các lĩnh vực như tóm tắt tài liệu, tùy chỉnh theo ngành, và tạo cũng như tư vấn mã nguồn kỹ thuật. Việc sử dụng ngày càng phổ biến các mô hình AI tạo sinh đã mang đến những trải nghiệm tùy chỉnh với yêu cầu kỹ thuật tối thiểu, và các tổ chức đang ngày càng tận dụng sức mạnh của các mô hình này để thúc đẩy đổi mới và nâng cao chất lượng dịch vụ trong nhiều lĩnh vực khác nhau, từ xử lý ngôn ngữ tự nhiên (NLP) đến tạo nội dung.\nTuy nhiên, việc sử dụng các mô hình AI tạo sinh trong môi trường doanh nghiệp cũng mang đến những thách thức riêng biệt. Các mô hình “dùng ngay” thường thiếu kiến thức chuyên sâu cần thiết cho một số lĩnh vực hoặc thuật ngữ đặc thù của tổ chức. Để giải quyết vấn đề này, các doanh nghiệp đang chuyển sang sử dụng các mô hình được tinh chỉnh, còn được gọi là mô hình ngôn ngữ lớn theo miền. Những mô hình này được tùy chỉnh để thực hiện các tác vụ chuyên biệt trong một hoặc nhiều miền nhỏ.\nTương tự, các tổ chức cũng đang tinh chỉnh mô hình AI tạo sinh cho nhiều lĩnh vực khác nhau như tài chính, bán hàng, marketing, du lịch, công nghệ thông tin, nhân sự, mua sắm, y tế và khoa học đời sống, cũng như dịch vụ khách hàng. Ngoài ra, các nhà cung cấp phần mềm độc lập cũng đang xây dựng các nền tảng AI tạo sinh có tính bảo mật cao, được quản lý và hỗ trợ đa người dùng.Khi nhu cầu về các giải pháp AI cá nhân hóa và chuyên biệt ngày càng tăng, các doanh nghiệp phải đối mặt với thách thức trong việc quản lý và triển khai hiệu quả hàng loạt mô hình tinh chỉnh cho nhiều trường hợp sử dụng và phân khúc khách hàng khác nhau. Từ phân tích hồ sơ xin việc và ghép kỹ năng công việc, đến tạo email chuyên biệt theo lĩnh vực và hiểu ngôn ngữ tự nhiên, nhiều công ty đang phải xử lý hàng trăm mô hình tinh chỉnh được phát triển cho các nhu cầu cụ thể.Thách thức này càng trở nên phức tạp hơn bởi vấn đề về khả năng mở rộng và hiệu quả chi phí. Các phương pháp phục vụ mô hình truyền thống có thể trở nên cồng kềnh và tốn tài nguyên, dẫn đến chi phí hạ tầng tăng cao, gánh nặng vận hành, và nguy cơ tắc nghẽn hiệu năng, do kích thước lớn và yêu cầu phần cứng cao để duy trì hiệu suất cho các mô hình nền .Sơ đồ dưới đây minh họa cách tiếp cận truyền thống trong việc phục vụ nhiều mô hình ngôn ngữ lớn.\nViệc tinh chỉnh các mô hình ngôn ngữ lớn LLMs là cực kỳ tốn kém do yêu cầu phần cứng và chi phí liên quan đến việc lưu trữ các phiên bản riêng biệt cho các tác vụ khác nhau.\nTrong bài viết này, chúng ta khám phá cách Low-Rank Adaptation (LoRA) có thể được sử dụng để giải quyết những thách thức đó một cách hiệu quả. Cụ thể, chúng ta thảo luận về việc sử dụng LoRA serving với LoRA eXchange (LoRAX) và các phiên bản GPU của Amazon Elastic Compute Cloud (Amazon EC2), cho phép các tổ chức quản lý và triển khai hiệu quả danh mục các mô hình đã được tinh chỉnh ngày càng tăng, tối ưu chi phí và cung cấp hiệu suất mượt mà cho khách hàng.\nLoRA là một kỹ thuật để điều chỉnh hiệu quả các mô hình ngôn ngữ lớn đã được tiền huấn luyện cho các tác vụ hoặc lĩnh vực mới bằng cách chèn các ma trận trọng số nhỏ có thể huấn luyện, gọi là adapter, vào mỗi lớp tuyến tính của mô hình tiền huấn luyện. Cách tiếp cận này cho phép thích ứng hiệu quả với số lượng tham số cần huấn luyện giảm đáng kể so với việc tinh chỉnh toàn bộ mô hình.Mặc dù LoRA cho phép thích ứng hiệu quả, việc lưu trữ các mô hình đã được tinh chỉnh thông thường lại hợp nhất các lớp đã tinh chỉnh với trọng số của mô hình gốc, vì vậy các tổ chức có nhiều biến thể đã được tinh chỉnh thường phải lưu trữ từng biến thể trên các phiên bản riêng biệt. Vì các adapter thu được tương đối nhỏ so với mô hình gốc và chỉ nằm ở vài lớp cuối của quá trình suy luận, cách triển khai phục vụ mô hình tùy chỉnh truyền thống này không hiệu quả cả về tài nguyên lẫn chi phí.\nMột giải pháp cho vấn đề này được cung cấp bởi một công cụ mã nguồn mở có tên LoRAX, cung cấp cơ chế hoán đổi trọng số trong quá trình suy luận để phục vụ nhiều biến thể của một FM nền tảng. LoRAX loại bỏ việc phải thiết lập thủ công quá trình gắn và tháo adapter với FM đã được tiền huấn luyện khi bạn chuyển đổi giữa việc suy luận các mô hình đã tinh chỉnh cho các miền hoặc trường hợp hướng dẫn khác nhau.\nVới LoRAX, bạn có thể tinh chỉnh một FM gốc cho nhiều tác vụ khác nhau, bao gồm tạo truy vấn SQL, điều chỉnh theo lĩnh vực ngành nghề, trích xuất thực thể và phản hồi theo hướng dẫn. Các biến thể khác nhau có thể được lưu trữ trên cùng một phiên bản EC2 thay vì phải sử dụng nhiều điểm cuối mô hình riêng biệt, giúp tiết kiệm chi phí mà không ảnh hưởng đến hiệu suất.\nTại sao chọn LoRAX cho việc triển khai LoRA trên AWS? Sự gia tăng phổ biến của việc tinh chỉnh LLMs đã dẫn đến sự xuất hiện của nhiều phương pháp container suy luận khác nhau để triển khai các adapter LoRA trên AWS. Hai phương pháp nổi bật nhất được khách hàng của chúng tôi sử dụng là LoRAX và vLLM.\nvLLM mang lại tốc độ suy luận nhanh và hiệu suất cao, rất phù hợp cho các ứng dụng yêu cầu khả năng phục vụ lớn với chi phí thấp, đặc biệt lý tưởng khi chạy nhiều mô hình tinh chỉnh có cùng mô hình gốc. Bạn có thể chạy các container suy luận vLLM bằng Amazon SageMaker, như được minh họa trong bài viết Efficient and cost-effective multi-tenant LoRA serving with Amazon SageMaker trên AWS Machine Learning Blog. Tuy nhiên, sự phức tạp của vLLM hiện nay khiến việc triển khai các tích hợp tùy chỉnh cho ứng dụng trở nên khó khăn hơn. vLLM cũng có khả năng hỗ trợ lượng tử hóa còn hạn chế.\nĐối với những ai đang tìm kiếm phương pháp xây dựng ứng dụng có sự hỗ trợ mạnh mẽ từ cộng đồng và khả năng tích hợp tùy chỉnh, LoRAX là một lựa chọn thay thế. LoRAX được xây dựng dựa trên container Text Generation Interface (TGI) của Hugging Face, được tối ưu hóa cho hiệu quả bộ nhớ và tài nguyên khi làm việc với các mô hình dựa trên transformer. Ngoài ra, LoRAX hỗ trợ các phương pháp lượng tử hóa như Activation-aware Weight Quantization (AWQ) và Half-Quadratic Quantization (HQQ).\nTổng quan giải pháp Container suy luận LoRAX có thể được triển khai trên một phiên bản EC2 G6 duy nhất, và các mô hình cùng adapter có thể được tải từ Amazon Simple Storage Service (Amazon S3) hoặc Hugging Face. Sơ đồ sau minh họa kiến trúc của giải pháp này.\nYêu cầu tiên quyết Để thực hiện hướng dẫn này, bạn cần có quyền truy cập vào các yêu cầu sau:\nMột tài khoản AWS\nQuyền thích hợp để triển khai các phiên bản EC2 G6. LoRAX được xây dựng với mục đích sử dụng công nghệ NVIDIA CUDA, và dòng phiên bản EC2 G6 là loại tiết kiệm chi phí nhất có bộ tăng tốc NVIDIA CUDA mới nhất. Cụ thể, G6.xlarge là lựa chọn tiết kiệm chi phí nhất cho hướng dẫn này tại thời điểm viết bài. Hãy đảm bảo rằng hạn ngạch (quota) đã được tăng trước khi triển khai.\n(Tùy chọn) Một sổ tay Jupyter trong Amazon SageMaker Studio hoặc SageMaker Notebook Instances. Sau khi các hạn ngạch được áp dụng cho tài khoản của bạn, bạn có thể sử dụng hình ảnh mặc định Studio Python 3 (Data Science) với phiên bản ml.t3.medium để chạy các đoạn mã sổ tay tùy chọn. Để xem danh sách đầy đủ các kernel có sẵn, hãy tham khảo danh sách Amazon SageMaker kernels.\nHướng dẫn thực hành Bài viết này sẽ hướng dẫn bạn tạo một phiên bản EC2, tải xuống và triển khai hình ảnh container, đồng thời lưu trữ một mô hình ngôn ngữ đã được huấn luyện sẵn cùng các adapter tùy chỉnh từ Amazon S3. Hãy làm theo danh sách kiểm tra các yêu cầu tiên quyết để đảm bảo rằng bạn có thể triển khai giải pháp này đúng cách.\nCấu hình chi tiết máy chủ Trong phần này, chúng tôi sẽ hướng dẫn cách cấu hình và tạo một phiên bản EC2 để lưu trữ LLM. Hướng dẫn này sử dụng lớp phiên bản EC2 G6 và triển khai mô hình Llama2 7B dung lượng 15 GB. Khuyến nghị nên có dung lượng bộ nhớ GPU khoảng gấp 1,5 lần dung lượng của mô hình để chạy suy luận (inference) trơn tru. Thông số bộ nhớ GPU có thể được tìm thấy trong phần Amazon ECS task definitions for GPU workloads.\nBạn có tùy chọn lượng tử hóa mô hình. Lượng tử hóa (quantization) mô hình ngôn ngữ giúp giảm kích thước trọng số mô hình xuống mức bạn chọn. Ví dụ, LLM mà chúng tôi sử dụng là Llama2 7B của Meta, mặc định có kích thước trọng số ở định dạng fp16, tức là số thực dấu chấm động 16-bit. Chúng ta có thể chuyển đổi trọng số mô hình sang int8 hoặc int4 (số nguyên 8-bit hoặc 4-bit) để giảm dung lượng bộ nhớ của mô hình lần lượt 50% và 25%. Trong hướng dẫn này, chúng tôi sử dụng định dạng fp16 mặc định của Llama2 7B từ Meta, vì vậy chúng tôi cần loại phiên bản có ít nhất 22 GB bộ nhớ GPU (VRAM).\nTùy theo thông số của mô hình ngôn ngữ, bạn cần điều chỉnh dung lượng lưu trữ Amazon Elastic Block Store (Amazon EBS) để đủ chỗ lưu mô hình gốc và trọng số adapter.\nĐể thiết lập máy chủ suy luận của bạn, hãy làm theo các bước sau:\nTrong bảng điều khiển Amazon EC2, chọn Launch instances, như minh họa trong hình bên dưới. Đối với tên, nhập LoRAX - Inference Server. Để mở AWS CloudShell, ở góc dưới bên trái của AWS Management Console chọn CloudShell, như minh họa trong ảnh chụp màn hình sau. Dán lệnh sau vào CloudShell và sao chép đoạn văn bản kết quả, như minh họa trong ảnh tiếp theo. Đây là Amazon Machine Image (AMI) ID mà bạn sẽ sử dụng:\naws ec2 describe-images --filters \u0026lsquo;Name=name,Values=Deep Learning OSS Nvidia Driver AMI GPU PyTorch 2.5*(Ubuntu*\u0026rsquo; \u0026lsquo;Name=state,Values=available\u0026rsquo; --query \u0026lsquo;sort_by(Images, \u0026amp;CreationDate)[-1].ImageId\u0026rsquo; --output text\nTrong thanh tìm kiếm Application and OS Images (Amazon Machine Image), nhập ami-0d2047d61ff42e139 và nhấn Enter trên bàn phím. Trong phần Selected AMI, nhập ID AMI mà bạn đã lấy được từ lệnh CloudShell. Trong Community AMIs, tìm kiếm Deep Learning OSS Nvidia Driver AMI GPU PyTorch 2.5.1 (Ubuntu 22.04) AMI. Chọn Select, như hiển thị trong ảnh chụp màn hình sau.\nChỉ định loại Instance là g6.xlarge. Tùy thuộc vào kích thước của mô hình, bạn có thể tăng kích thước instance để đáp ứng nhu cầu. Để biết thông tin về bộ nhớ GPU theo từng loại instance, hãy truy cập trang Amazon EC2 task definitions for GPU workloads. (Tùy chọn) Trong phần Key pair (login), hãy tạo một key pair mới hoặc chọn một key pair có sẵn nếu bạn muốn dùng để kết nối với instance qua SSH. Trong Network settings, chọn Edit như trong ảnh chụp màn hình. Giữ nguyên các thiết lập mặc định cho VPC, Subnet và Auto-assign public IP Trong phần Firewall (security groups), tại Security group name, nhập Inference Server Security Group. FTrong Description, nhập Security Group for Inference Server. Trong Inbound Security Group Rules, chỉnh sửa Security group rule 1 để giới hạn truy cập SSH chỉ cho địa chỉ IP của bạn bằng cách thay đổi Source type thành My IP. Chọn Add security group rule.\nCấu hình Security group rule 2 bằng cách thay đổi Type thành All ICMP-IPv4 và Source Type thành My IP. Điều này đảm bảo rằng máy chủ chỉ có thể truy cập được từ địa chỉ IP của bạn, tránh bị truy cập bởi những đối tượng xấu.\nTrong phần Configure storage, đặt kích thước Root volume size là 128 GiB để đủ dung lượng lưu trữ mô hình cơ sở và trọng số adapter. Đối với các mô hình lớn hơn hoặc nhiều adapter hơn, bạn có thể cần tăng giá trị này. Thẻ mô hình (model card) của hầu hết các mô hình mã nguồn mở đều có thông tin chi tiết về kích thước và cách sử dụng.Chúng tôi gợi ý bắt đầu với 128 GB vì việc tải nhiều adapter cùng với trọng số mô hình có thể chiếm nhiều dung lượng. Khi tính cả không gian cho hệ điều hành, driver, dependencies và tệp dự án, 128 GB là mức an toàn ban đầu trước khi điều chỉnh tăng hoặc giảm.Sau khi thiết lập dung lượng lưu trữ mong muốn, chọn menu thả xuống Advanced details. Trong phần IAM instance profile, hãy chọn hoặc tạo một IAM instance profile có quyền đọc S3. Chọn Launch instance. Khi instance đã khởi chạy xong, chọn SSH hoặc Instance connect để kết nối đến instance và nhập các lệnh sau:\nsudo apt update\nsudo systemctl start docker\nsudo nvidia-ctk runtime configure --runtime=docker\nsudo systemctl restart docker Cài đặt container và khởi chạy máy chủ Máy chủ hiện đã được cấu hình đúng để tải và chạy phần mềm phục vụ.\nNhập các lệnh sau để tải xuống và triển khai image Docker của LoRAX. Để biết thêm thông tin, hãy tham khảo phần chạy container với LLM gốc. Chỉ định một mô hình từ Hugging Face hoặc từ thư mục lưu trữ cục bộ và tải mô hình đó để thực hiện suy luận. Thay thế các tham số trong lệnh cho phù hợp với nhu cầu của bạn (ví dụ: \u0026lt;huggingface-access-token\u0026gt;).\nThêm thẻ -d như trong ví dụ sẽ giúp quá trình tải và cài đặt chạy ở chế độ nền. Quá trình này có thể mất đến 30 phút để hoàn tất việc cấu hình. Sử dụng các lệnh Docker docker ps và docker logs \u0026lt;container-name\u0026gt;, để xem tiến trình của container Docker và quan sát khi nào container hoàn tất cài đặt. Lệnh docker logs \u0026lt;container-name\u0026gt; --follow sẽ tiếp tục hiển thị luồng log mới từ container để bạn có thể theo dõi liên tục.\nmodel=meta-llama/Llama-2-7b-hf\nvolume=$PWD/data\ntoken=\u0026lt;huggingface-access-token\u0026gt;\ndocker run -d --gpus all --shm-size 1g -p 8080:80 -v $volume:/data -e HUGGING_FACE_HUB_TOKEN=$token ghcr.io/predibase/lorax:main --model-id $model\nKiểm tra máy chủ và adapter Khi chạy container ở chế độ nền bằng thẻ -d , bạn có thể gửi yêu cầu đến máy chủ (server) để kiểm tra phản hồi.Khi bạn chỉ định model-id là một ID mô hình trên Hugging Face, LoRAX sẽ tải mô hình đó trực tiếp vào bộ nhớ từ Hugging Face.\nTuy nhiên, cách này không được khuyến nghị cho môi trường production vì việc phụ thuộc vào Hugging Face có thể dẫn đến lỗi nếu mô hình hoặc adapter không khả dụng.Khuyến nghị nên lưu trữ mô hình cục bộ trên Amazon S3, Amazon EBS, hoặc Amazon Elastic File System (Amazon EFS) để đảm bảo khả năng triển khai ổn định.Phần sau của bài viết sẽ hướng dẫn cách tải mô hình và adapter từ S3 khi cần.\nLoRAX cũng có thể tải tệp adapter trực tiếp từ Hugging Face trong thời gian chạy. Bạn có thể sử dụng tính năng này bằng cách thêm adapter_id và adapter_source vào phần nội dung (body) của yêu cầu. Lần đầu tiên một adapter mới được yêu cầu, quá trình tải có thể mất một khoảng thời gian, nhưng các yêu cầu sau đó sẽ nhanh hơn vì adapter đã được lưu trong bộ nhớ.\nNhập lệnh sau để gửi yêu cầu đến mô hình gốc: curl 127.0.0.1:8080/generate \\\n-X POST \\\nd \u0026lsquo;{\n\u0026ldquo;inputs\u0026rdquo;: \u0026ldquo;why is the sky blue\u0026rdquo;,\n\u0026ldquo;parameters\u0026rdquo;: {\n\u0026ldquo;max_new_tokens\u0026rdquo;: 6\n}\n}\u0026rsquo; \\\nH \u0026lsquo;Content-Type: application/json\u0026rsquo;\nEnter the following command to prompt the base model with the specified adapter: curl 127.0.0.1:8080/generate \\\n-X POST \\\n-d \u0026lsquo;{\n\u0026ldquo;inputs\u0026rdquo;: \u0026ldquo;why is the sky blue\u0026rdquo;,\n\u0026ldquo;parameters\u0026rdquo;: {\n\u0026ldquo;max_new_tokens\u0026rdquo;: 64,\n\u0026ldquo;adapter_id\u0026rdquo;: \u0026ldquo;vineetsharma/qlora-adapter-Llama-2-7b-hf-databricks-dolly-15k\u0026rdquo;,\n\u0026ldquo;adapter_source\u0026rdquo;: \u0026ldquo;hub\u0026rdquo;\n}\n}\u0026rsquo; \\\n-H \u0026lsquo;Content-Type: application/json\u0026rsquo;\n[Tùy chọn] Tạo adapter tùy chỉnh bằng SageMaker training và PEFT\nCác tác vụ tinh chỉnh (fine-tuning) thông thường cho LLM thường hợp nhất trọng số của adapter với mô hình gốc. Tuy nhiên, sử dụng phần mềm như thư viện PEFT của Hugging Face cho phép tinh chỉnh mà vẫn tách biệt các adapter.\nLàm theo các bước được trình bày trong bài viết in this AWS Machine Learning blog post để tinh chỉnh mô hình Llama 2 của Meta và lấy adapter LoRA được tách riêng trong Amazon S3.\n[Tùy chọn] Sử dụng adapter từ Amazon S3 LoRAX có thể tải tệp adapter từ Amazon S3 trong thời gian chạy. Bạn có thể sử dụng khả năng này bằng cách thêm adapter_id vả adapter_source trong phần nội dung của yêu cầu. Lần đầu tiên một adapter mới được yêu cầu, việc tải có thể mất một khoảng thời gian, nhưng các yêu cầu sau đó sẽ được tải nhanh từ bộ nhớ máy chủ.Đây là phương pháp tối ưu khi chạy LoRAX trong môi trường production so với việc nhập từ Hugging Face vì nó không phụ thuộc vào các thành phần runtime bên ngoài.\ncurl 127.0.0.1:8080/generate \\\n-X POST \\\n-d \u0026lsquo;{\n\u0026ldquo;inputs\u0026rdquo;: \u0026ldquo;What is process mining?\u0026rdquo;,\n\u0026ldquo;parameters\u0026rdquo;: {\n\u0026ldquo;max_new_tokens\u0026rdquo;: 64,\n\u0026ldquo;adapter_id\u0026rdquo;: \u0026ldquo;\u0026lt;your-adapter-s3-bucket-path\u0026gt;\u0026rdquo;,\n\u0026ldquo;adapter_source\u0026rdquo;: \u0026ldquo;s3\u0026rdquo;\n}\n}\u0026rsquo; \\\n-H \u0026lsquo;Content-Type: application/json\u0026rsquo;\n[Tùy chọn] Sử dụng mô hình tùy chỉnh từ Amazon S3 LoRAX cũng có thể tải các mô hình ngôn ngữ tùy chỉnh từ Amazon S3. Nếu kiến trúc mô hình được hỗ trợ trong tài liệu của LoRAX, bạn có thể chỉ định tên bucket để lấy trọng số, như trong ví dụ mã dưới đây. Tham khảo phần tùy chọn trước về việc tách trọng số adapter khỏi trọng số mô hình gốc để tùy chỉnh mô hình ngôn ngữ của riêng bạn.\nvolume=$PWD/data\nbucket_name=\u0026lt;s3-bucket-name\u0026gt;\nmodel=\u0026lt;model-directory-name\u0026gt;\ndocker run --gpus all --shm-size 1g -e PREDIBASE_MODEL_BUCKET=$bucket_name -p 8080:80 -v $volume:/data ghcr.io/predibase/lorax:latest --model-id $model\nTriển khai ổn định bằng Amazon S3 cho việc lưu trữ mô hình và adapter Lưu trữ mô hình và adapter trong Amazon S3 mang lại giải pháp đáng tin cậy hơn cho việc triển khai nhất quán so với phụ thuộc vào các dịch vụ bên thứ ba như Hugging Face. Bằng cách tự quản lý kho lưu trữ, bạn có thể thiết lập các giao thức mạnh mẽ để đảm bảo mô hình và adapter luôn sẵn sàng khi cần thiết. Ngoài ra, cách tiếp cận này cho phép bạn duy trì kiểm soát phiên bản và tách biệt tài sản của mình khỏi nguồn bên ngoài, điều này rất quan trọng cho việc tuân thủ quy định và quản lý.\nĐể có thêm sự linh hoạt, bạn có thể sử dụng hệ thống tệp ảo như Amazon EFS hoặc Amazon FSx for Lustre. Bạn có thể sử dụng các dịch vụ này để gắn kết cùng một mô hình và adapter trên nhiều phiên bản, giúp truy cập liền mạch trong môi trường có auto scaling. Điều này có nghĩa là tất cả các phiên bản, dù mở rộng hay thu hẹp, đều có quyền truy cập không gián đoạn vào tài nguyên cần thiết, giúp tăng độ tin cậy và khả năng mở rộng của hệ thống.\nSo sánh chi phí và tư vấn về khả năng mở rộng Sử dụng container suy luận LoRAX trên các phiên bản EC2 giúp giảm đáng kể chi phí lưu trữ nhiều phiên bản tinh chỉnh của mô hình ngôn ngữ bằng cách lưu tất cả adapter trong bộ nhớ và hoán đổi linh hoạt trong thời gian chạy. Vì adapter LLM thường chỉ chiếm một phần nhỏ so với mô hình gốc, bạn có thể mở rộng hạ tầng hiệu quả dựa trên mức sử dụng máy chủ thay vì từng biến thể riêng lẻ. Adapter LoRA thường có kích thước bằng khoảng 1/10 đến 1/4 mô hình gốc, tuy nhiên điều này còn phụ thuộc vào cách triển khai và độ phức tạp của tác vụ mà adapter được huấn luyện.\nTrong ví dụ trước, các adapter thu được từ quá trình huấn luyện có dung lượng khoảng 5 MB.\nMặc dù dung lượng này phụ thuộc vào kiến trúc mô hình, bạn vẫn có thể hoán đổi hàng nghìn biến thể tinh chỉnh trên cùng một phiên bản mà gần như không ảnh hưởng đến tốc độ suy luận. Khuyến nghị sử dụng các phiên bản có dung lượng bộ nhớ GPU khoảng 150% so với tổng kích thước mô hình và adapter để chứa mô hình, adapter, và vùng lưu trữ KV cache (hoặc attention cache) trong VRAM. Để xem thông số bộ nhớ GPU, hãy tham khảo Amazon ECS task definitions for GPU workloads.\nTùy thuộc vào mô hình gốc và số lượng adapter tinh chỉnh, bạn có thể huấn luyện và triển khai hàng trăm hoặc hàng nghìn mô hình ngôn ngữ tùy chỉnh chia sẻ cùng một mô hình gốc, bằng cách sử dụng LoRAX để hoán đổi adapter linh hoạt. Với cơ chế hoán đổi adapter, nếu bạn có năm biến thể tinh chỉnh, bạn có thể tiết kiệm đến 80% chi phí lưu trữ vì tất cả adapter tùy chỉnh có thể dùng chung trong cùng một phiên bản.\nMẫu triển khai trong Amazon EC2 có thể được sử dụng để triển khai nhiều phiên bản, với các tùy chọn cân bằng tải hoặc tự động mở rộng. Ngoài ra, bạn có thể sử dụng AWS Systems Manager để triển khai các bản vá hoặc thay đổi. Như đã đề cập trước đó, một hệ thống tệp chia sẻ có thể được sử dụng giữa tất cả các tài nguyên EC2 được triển khai để lưu trọng số LLM cho nhiều adapter, giúp truyền dữ liệu đến các phiên bản nhanh hơn so với Amazon S3. Sự khác biệt giữa việc sử dụng hệ thống tệp chia sẻ như Amazon EFS so với truy cập trực tiếp S3 là số bước cần thiết để tải trọng số và adapter vào bộ nhớ. Với S3, adapter và trọng số phải được chuyển vào hệ thống tệp cục bộ trước khi tải. Trong khi đó, hệ thống tệp chia sẻ không cần chuyển tệp cục bộ và có thể tải trực tiếp. Tuy nhiên, vẫn có những điểm đánh đổi cần xem xét khi triển khai. Bạn cũng có thể sử dụng Amazon API Gateway làm điểm cuối API cho các ứng dụng REST.\nLưu trữ máy chủ LoRAX cho nhiều mô hình trong môi trường production Nếu bạn dự định sử dụng nhiều mô hình FM tùy chỉnh cho các tác vụ cụ thể với LoRAX, hãy làm theo hướng dẫn này để lưu trữ nhiều biến thể mô hình. Tham khảo bài viết AWS blog on hosting text classification with BERT để thực hiện định tuyến tác vụ giữa các mô hình chuyên biệt. Để xem ví dụ triển khai về lưu trữ mô hình hiệu quả bằng cơ chế hoán đổi adapter, hãy tham khảo LoRA Land, được phát hành bởi Predibase, tổ chức đứng sau LoRAX. LoRA Land là tập hợp gồm 25 biến thể tinh chỉnh của mô hình Mistral-7b từ Mistral.ai, hoạt động hiệu quả hơn so với nhiều mô hình LLM hàng đầu khác khi được lưu trữ sau một endpoint duy nhất. Sơ đồ sau đây minh họa kiến trúc của hệ thống.\nDọn dẹp Trong hướng dẫn này, chúng ta đã tạo các nhóm bảo mật (security groups), một S3 bucket, một phiên bản sổ tay SageMaker (tùy chọn), và một máy chủ suy luận EC2. Việc quan trọng là phải chấm dứt các tài nguyên được tạo trong quá trình thực hiện để tránh phát sinh thêm chi phí:\nXóa S3 bucket Chấm dứt máy chủ suy luận EC2 Chấm dứt phiên bản sổ tay SageMaker Kết luận Sau khi làm theo hướng dẫn này, bạn có thể thiết lập một phiên bản EC2 với LoRAX để lưu trữ và phục vụ các mô hình ngôn ngữ, lưu trữ và truy cập trọng số mô hình tùy chỉnh cùng các bộ điều hợp trong Amazon S3, và quản lý các mô hình được huấn luyện sẵn cũng như mô hình tùy chỉnh và các biến thể của chúng bằng SageMaker. LoRAX cung cấp một phương pháp tiết kiệm chi phí cho những ai muốn lưu trữ nhiều mô hình ngôn ngữ ở quy mô lớn. Để biết thêm thông tin về cách làm việc với trí tuệ nhân tạo sinh trên AWS, hãy tham khảo bài viết Announcing New Tools for Building with Generative AI on AWS.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://thienluhoan.github.io/workshop-template/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]